{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import json\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from __future__ import unicode_literals\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./News/train.csv\", sep='\\t', error_bad_lines= False , encoding= 'utf-8')\n",
    "df_test = pd.read_csv(\"./News/test.csv\", sep='\\t', error_bad_lines= False , encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \n",
    "    def __init__(self, train_data=\"./News/train.csv\", test_data=\"./News/test.csv\", mode=\"train\"):\n",
    "        self.read_data(train_data, test_data)\n",
    "        self.plot_distribution(mode=mode)\n",
    "        self.clean_text(mode=mode)\n",
    "        self.count_words()\n",
    "        self.map_word_index()\n",
    "        setattr(self,f\"{mode}\", self.tokenizer())\n",
    "        \n",
    "        \n",
    "    def first_item(self):\n",
    "        return self.train_data[0]\n",
    "    \n",
    "    def read_data(self ,train_data, test_data):\n",
    "        self.train_data = pd.read_csv(train_data, sep=\"\\t\", error_bad_lines=False, encoding=\"utf-8\")\n",
    "        self.train_data = self.train_data.dropna(subset=['category'])\n",
    "        self.train_data = self.train_data.loc[self.train_data['category']!='category']\n",
    "        self.test_data = pd.read_csv(test_data, sep=\"\\t\", error_bad_lines=False, encoding=\"utf-8\")\n",
    "        self.test_data = self.test_data.dropna(subset=['category'])\n",
    "        self.test_data = self.test_data.loc[self.test_data['category']!='category']\n",
    "    \n",
    "    def plot_distribution(self, mode=\"train\"):\n",
    "        if mode==\"train\":\n",
    "            self.train_data['category'].value_counts(sort=False).plot(kind='bar')\n",
    "        else:\n",
    "            self.test_data['category'].value_counts(sort=False).plot(kind='bar')\n",
    "        \n",
    "    \n",
    "    def clean_text(self, mode=\"train\"):\n",
    "        ws = []\n",
    "        source = self.train_data.text\n",
    "        if mode==\"test\":\n",
    "            source = self.test_data.text\n",
    "        for a in source.astype(str):\n",
    "            w = [tk for tk in word_tokenize(a) if tk.isalpha()] + ['<eos>']\n",
    "            ws.append(w)\n",
    "        self.cleaned_data = ws\n",
    "        www = []\n",
    "        for w in self.cleaned_data:\n",
    "            ww = []\n",
    "            for item in w:\n",
    "                if \".\" in item:\n",
    "                    if item.split(\".\")[0]!='':\n",
    "                        ww.extend([item.split(\".\")[0]])\n",
    "                elif not item.encode().isalpha():\n",
    "                    ww.append(item)\n",
    "            www.append(ww)\n",
    "            \n",
    "        self.tokenized_data = www\n",
    "        print(www[:1])\n",
    "            \n",
    "    \n",
    "    def count_words(self):\n",
    "        www = self.tokenized_data\n",
    "        di = dict()\n",
    "        for ww in www:\n",
    "            for i in ww:\n",
    "                if i not in di:\n",
    "                    di[i] = 1\n",
    "                else:\n",
    "                    di[i]+=1\n",
    "        srt = sorted(di.items(), key=lambda item: item[1],reverse=True)\n",
    "        asrt = srt\n",
    "        self.tokens = asrt\n",
    "        with open(\"‫‪frequencies‬‬.txt\",\"w\") as file:\n",
    "            file.write(str(srt[:200]))\n",
    "        dictionary = dict(asrt)\n",
    "        print(f\"tokens={sum(di.values())}, and unique tokens are={len(srt)}\")\n",
    "        self.frequencies_dict = dictionary\n",
    "        self.n_tokens = sum(di.values())\n",
    "        self.n_unique_tokens = len(srt)\n",
    "\n",
    "    def map_word_index(self):\n",
    "        vocabs = self.frequencies_dict.keys()\n",
    "        self.word_to_index = {}\n",
    "        self.index_to_word = {}\n",
    "        for index , vocab in enumerate(vocabs):\n",
    "            self.index_to_word[index] = vocab\n",
    "            self.word_to_index[vocab] = index\n",
    "        print(\"Saving dictionary...\")\n",
    "        with open(\"‫‪indeces‬‬.json\",\"w\") as file:\n",
    "            json.dump(self.word_to_index, file, ensure_ascii=False)\n",
    "        print(\"Saving dictionary finished\")\n",
    "        \n",
    "    \n",
    "    def tokenizer(self):\n",
    "        www = []\n",
    "        for w in self.tokenized_data:\n",
    "            ww = []\n",
    "            for item in w:\n",
    "                ww.append(self.word_to_index[item])\n",
    "            www.append(torch.tensor(ww).type(torch.int64))\n",
    "            \n",
    "        self.tokenized_tokens = www\n",
    "        print(www[0])\n",
    "        return torch.cat(www)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['به', 'گزارش', 'خبرنگار', 'حوزه', 'میراث', 'و', 'فرهنگی', 'باشگاه', 'خبرنگاران', 'جوان', 'محمد', 'حسن', 'خان', 'اعتماد', 'السلطنه', 'به', 'نقل', 'از', 'برخی', 'منابع', 'اسفراین', 'چمن', 'کالپوش', 'چمن', 'کالپوش', 'بر', 'اساس', 'آنچه', 'در', 'اعتقادات', 'اهالی', 'منطقه', 'مشهود', 'است', 'آخرین', 'منزلگاه', 'داریوش', 'سوم', 'است', 'بنابراین', 'باید', 'دشت', 'اسفراین', 'را', 'جولانگاه', 'مقدونیان', 'دانست', 'این', 'دشت', 'از', 'دستبرد', 'و', 'سم', 'ستوران', 'یونانی', 'در', 'امان', 'بنا', 'بر', 'این', 'گزارش', 'شهر', 'اسفراین', 'امروزی', 'در', 'شمال', 'غربی', 'استان', 'خراسان', 'شمالی', 'قرار', 'این', 'شهر', 'دربرگیرنده', 'بیش', 'از', 'بقعه', 'از', 'بزرگان', 'و', 'امامزادگان', 'است', 'شایان', 'ذکر', 'است', 'شهر', 'فعلی', 'اسفراین', 'از', 'محله', 'تشکیل', 'شده', 'و', 'زیستگاه', 'حیواناتی', 'چون', 'آهو', 'گرگ', 'گورکن', 'خرگوش', 'روباه', 'گراز', 'پلنگ', 'کفتار', 'و', 'بز', 'کوهی', 'است', 'منطقه', 'ساری', 'گل', 'در', 'شمال', 'شرقی', 'اسفراین', 'قرار', 'گفتنی', 'است', 'ابوعبدلله', 'حمد', 'بن', 'احمد', 'مقدسی', 'در', 'خصوص', 'اسفراین', 'اسفراین', 'روستایی', 'بزرگ', 'و', 'مرکز', 'انگور', 'خوب', 'و', 'کشتزار', 'است', 'جاده', 'گرگان', 'آن', 'را', 'به', 'دو', 'نیمه', 'شهر', 'آن', 'به', 'همین', 'نام', 'است', 'آباد', 'و', 'گرانقدر', 'است', 'از', 'نهری', 'که', 'از', 'کوه', 'در', 'این', 'روستا', 'از', 'آن', 'نیست', 'مردم', 'آن', 'اهل', 'حدیثند', 'خاطرنشان', 'ابوعبدالله', 'الحاکم', 'مؤلف', 'تاریخ', 'نیشابور', 'نیز', 'اسفراین', 'را', 'شهری', 'خوش', 'آب', 'و', 'هوا', 'ذکر', 'است', 'و', 'قباد', 'پادشاه', 'ساسانی', 'نام', 'اسفراین', 'را', 'به', 'علت', 'داشتن', 'آب', 'و', 'هوای', 'خوب', 'مهرجان', 'است', '<eos>']]\n",
      "tokens=28964490, and unique tokens are=214074\n",
      "Saving dictionary...\n",
      "Saving dictionary finished\n",
      "tensor([     2,     35,     84,     88,   1483,      0,    165,     20,     24,\n",
      "            49,    222,    560,   3531,    917,  23395,      2,    105,      3,\n",
      "           132,    333,  13734,   6350,  56673,   6350,  56673,     16,    166,\n",
      "           644,      1,   6587,   2426,     91,   5789,      8,    324,  20941,\n",
      "          4769,    504,      8,    619,     33,   5719,  13734,      7,  30109,\n",
      "        117095,    680,      4,   5719,      3,  12824,      0,   5890, 117096,\n",
      "          9330,      1,   4127,   1249,     16,      4,     35,    111,  13734,\n",
      "          5565,      1,    752,    783,    114,   1027,    678,     36,      4,\n",
      "           111,  13650,    210,      3,  10863,      3,   3320,      0,   9148,\n",
      "             8,   2450,    795,      8,    111,   1407,  13734,      3,   1668,\n",
      "           393,     39,      0,  12444,  18910,    368,  16405,   9127,  72247,\n",
      "         19744,  11971,  30110,  11251,  51889,      0,  13735,   9773,      8,\n",
      "            91,   5261,    498,      1,    752,   1217,  13734,     36,    632,\n",
      "             8, 117097,   5655,    845,    892,   8110,      1,    112,  13734,\n",
      "         13734,   2164,    230,      0,    272,   7488,    421,      0,  62768,\n",
      "             8,   1360,   5601,     13,      7,      2,     43,    810,    111,\n",
      "            13,      2,    155,    191,      8,   1466,      0,   8111,      8,\n",
      "             3,  86654,      5,      3,   3754,      1,      4,   2559,      3,\n",
      "            13,    127,     48,     13,   1008, 117098,    405,  40722,  72248,\n",
      "         13268,    439,   7562,     32,  13734,      7,    695,   1784,    251,\n",
      "             0,    634,    795,      8,      0,  15662,   2710,  10826,    191,\n",
      "         13734,      7,      2,    479,    869,    251,      0,   1639,    421,\n",
      "         72249,      8,     15])\n",
      "[['به', 'گزارشحوزه', 'ادبیات', 'باشگاه', 'خبرنگاران', 'این', 'کتاب', 'شامل', 'عکس', 'های', 'هوایی', 'از', 'مناظر', 'ایران', 'با', 'شعرهایی', 'از', 'مولف', 'که', 'دل', 'نوشته', 'های', 'وی', 'روی', 'تصاویر', 'است', 'به', 'دو', 'زبان', 'فارسی', 'و', 'انگلیسی', 'طراحی', 'و', 'به', 'چاپ', 'این', 'کتاب', 'در', 'قطع', 'خشتی', 'و', 'صفحه', 'تمام', 'رنگی', 'با', 'تیراژ', 'عدد', 'توسط', 'نشر', 'تحریر', 'خیال', 'منتشر', 'شده', 'و', 'در', 'اختیار', 'علاقمندان', 'قرار', 'ویژگی', 'عکس', 'های', 'هوایی', 'این', 'کتاب', 'انتزاعی', 'بودن', 'تاکید', 'بر', 'فرم', 'و', 'جزئیات', 'تصاویر', 'می', 'باشد', 'که', 'کمتر', 'در', 'عکس', 'های', 'هوایی', 'عکاسان', 'ایرانی', 'یونس', 'کلاهدوز', 'استاد', 'خلبانی', 'است', 'که', 'زیادی', 'را', 'برای', 'ثبت', 'این', 'لحظه', 'ها', 'تلاش', 'نموده', 'و', 'در', 'مقدمهکتاب', 'چشم', 'آسمان', 'می', 'نویسد', 'این', 'کتاب', 'نگاهی', 'است', 'از', 'آسمان', 'به', 'زمین', 'و', 'زندگی', 'فارغ', 'از', 'قواعد', 'معمول', 'عکاسی', 'با', 'توجه', 'به', 'جزئیات', 'تصاویر', 'برخلاف', 'آنچه', 'در', 'عکس', 'های', 'هوایی', 'ایران', 'رایج', 'است', 'این', 'کتاب', 'عکس', 'نوشته', 'هایی', 'است', 'در', 'لحظه', 'های', 'منحصر', 'بفرد', 'و', 'شوق', 'انتقال', 'این', 'احساس', 'و', 'نگاه', 'به', 'مخاطبان', 'می', 'باشد', 'لازم', 'به', 'ذکر', 'است', 'پیش', 'از', 'این', 'عکاس', 'سوئیسی', 'به', 'نام', 'گئورگ', 'گریستر', 'با', 'شباهتهایی', 'به', 'لحاظ', 'سبک', 'عکاسی', 'ایران', 'از', 'آسمان', 'به', 'تصویر', 'که', 'نمایشگاهی', 'را', 'نیز', 'با', 'عنوان', 'بهشت', 'گمشده', 'بر', 'فراز', 'ایران', 'را', 'به', 'نمایش', 'درآورد', 'قیمت', 'پشت', 'جلد', 'این', 'کتاب', 'هزار', 'تومان', 'است', 'انتهای', '<eos>']]\n",
      "tokens=5241355, and unique tokens are=84795\n",
      "Saving dictionary...\n",
      "Saving dictionary finished\n",
      "tensor([    2,  9705,  1851,    20,    23,     4,   391,   588,  1291,    12,\n",
      "          699,     3, 13061,    26,     6, 37049,     3, 21106,     5,  1201,\n",
      "         1685,    12,    22,   122,  1073,     8,     2,    41,   735,  1942,\n",
      "            0,  1465,   695,     0,     2,  1287,     4,   391,     1,  1184,\n",
      "        22687,     0,  1016,   172,  3897,     6, 11143,  1550,   192,  2105,\n",
      "         8899,  4153,   487,    39,     0,     1,   527,  3782,    37,  1586,\n",
      "         1291,    12,   699,     4,   391, 16846,   396,   181,    16,  3414,\n",
      "            0,  1929,  1073,    10,    99,     5,   728,     1,  1291,    12,\n",
      "          699,  6093,   316,  7078, 18619,  1017, 10484,     8,     5,   274,\n",
      "            7,     9,   412,     4,  1286,    29,   182,  2834,     0,     1,\n",
      "        48833,   718,  2346,    10,  6699,     4,   391,  2697,     8,     3,\n",
      "         2346,     2,   484,     0,   267,  2775,     3,  5706,  2915,  5026,\n",
      "            6,    91,     2,  1929,  1073,  2624,   667,     1,  1291,    12,\n",
      "          699,    26,  3987,     8,     4,   391,  1291,  1685,   381,     8,\n",
      "            1,  1286,    12,  3171, 16847,     0,  5516,   545,     4,   862,\n",
      "            0,   609,     2,  1373,    10,    99,   218,     2,   776,     8,\n",
      "          104,     3,     4,  4315, 10275,     2,   189, 31196, 48834,     6,\n",
      "        48835,     2,   821,  1294,  5026,    26,     3,  2346,     2,  1220,\n",
      "            5,  5027,     7,    31,     6,    56,  3103,  7922,    16,  3255,\n",
      "           26,     7,     2,   349,  5176,   170,   768,  3898,     4,   391,\n",
      "           68,   147,     8,   131,    15])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = DataPreprocessor()\n",
    "data_test = DataPreprocessor(mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[فرهنگی هنری, فرهنگی هنری, فرهنگی هنری, فرهنگی هنری, فرهنگی هنری, ..., ورزشی, ورزشی, ورزشی, ورزشی, ورزشی]\n",
       "Length: 117153\n",
       "Categories (10, object): [اجتماعی, اقتصادی, بین‌الملل, سیاسی, ..., فضای مجازی, فیلم و صوت, وب‌گردی, ورزشی]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Categorical(data_train.train_data.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.text)==len(self.label)\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"text\": self.text[idx], \"label\": self.label[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_train.tokenized_tokens, pd.Categorical(data_train.train_data.category).codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(data_test.tokenized_tokens, pd.Categorical(data_test.test_data.category).codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "#     for (_text, _label) in batch:\n",
    "    for _item in batch:\n",
    "         _label, _text = _item[\"label\"], _item[\"text\"]\n",
    "         label_list.append(_label)\n",
    "         processed_text = _text\n",
    "         text_list.append(processed_text)\n",
    "#          print(\"&&&&&&&\", processed_text, _text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list, text_list, offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(data_train.word_to_index)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1739 batches | accuracy    0.764\n",
      "| epoch   1 |  1000/ 1739 batches | accuracy    0.758\n",
      "| epoch   1 |  1500/ 1739 batches | accuracy    0.759\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 25.67s | valid accuracy    0.770 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1739 batches | accuracy    0.766\n",
      "| epoch   2 |  1000/ 1739 batches | accuracy    0.765\n",
      "| epoch   2 |  1500/ 1739 batches | accuracy    0.763\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 26.02s | valid accuracy    0.775 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1739 batches | accuracy    0.768\n",
      "| epoch   3 |  1000/ 1739 batches | accuracy    0.768\n",
      "| epoch   3 |  1500/ 1739 batches | accuracy    0.765\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 26.86s | valid accuracy    0.765 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 1739 batches | accuracy    0.789\n",
      "| epoch   4 |  1000/ 1739 batches | accuracy    0.785\n",
      "| epoch   4 |  1500/ 1739 batches | accuracy    0.788\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 26.76s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 1739 batches | accuracy    0.789\n",
      "| epoch   5 |  1000/ 1739 batches | accuracy    0.786\n",
      "| epoch   5 |  1500/ 1739 batches | accuracy    0.789\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 26.75s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 1739 batches | accuracy    0.791\n",
      "| epoch   6 |  1000/ 1739 batches | accuracy    0.790\n",
      "| epoch   6 |  1500/ 1739 batches | accuracy    0.794\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 26.89s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 1739 batches | accuracy    0.793\n",
      "| epoch   7 |  1000/ 1739 batches | accuracy    0.791\n",
      "| epoch   7 |  1500/ 1739 batches | accuracy    0.790\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 28.46s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 1739 batches | accuracy    0.790\n",
      "| epoch   8 |  1000/ 1739 batches | accuracy    0.790\n",
      "| epoch   8 |  1500/ 1739 batches | accuracy    0.793\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 27.66s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 1739 batches | accuracy    0.790\n",
      "| epoch   9 |  1000/ 1739 batches | accuracy    0.791\n",
      "| epoch   9 |  1500/ 1739 batches | accuracy    0.790\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 28.93s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 1739 batches | accuracy    0.786\n",
      "| epoch  10 |  1000/ 1739 batches | accuracy    0.795\n",
      "| epoch  10 |  1500/ 1739 batches | accuracy    0.791\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 27.95s | valid accuracy    0.793 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.306\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
